package com.iot.jobs;

/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

import org.apache.flink.api.common.functions.FilterFunction;
import org.apache.flink.api.common.functions.FlatMapFunction;
import org.apache.flink.api.common.functions.MapFunction;
import org.apache.flink.api.common.restartstrategy.RestartStrategies;
import org.apache.flink.api.java.tuple.Tuple;
import org.apache.flink.api.java.tuple.Tuple2;
import org.apache.flink.runtime.state.filesystem.FsStateBackend;
import org.apache.flink.streaming.api.CheckpointingMode;
import org.apache.flink.streaming.api.datastream.DataStream;
import org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
import org.apache.flink.streaming.api.functions.sink.SinkFunction;
import org.apache.flink.streaming.api.functions.windowing.AllWindowFunction;
import org.apache.flink.streaming.api.functions.windowing.WindowFunction;
import org.apache.flink.streaming.api.windowing.time.Time;
import org.apache.flink.streaming.api.windowing.windows.TimeWindow;
import org.apache.flink.streaming.connectors.twitter.TwitterSource;
import org.apache.flink.util.Collector;
import org.apache.log4j.Logger;
import org.codehaus.jackson.JsonNode;
import org.codehaus.jackson.map.ObjectMapper;
import org.influxdb.InfluxDB;
import org.influxdb.InfluxDBFactory;
import org.influxdb.dto.BatchPoints;
import org.influxdb.dto.Point;
import org.json.JSONException;
import org.json.JSONObject;

import com.google.common.collect.Iterables;
import com.google.gson.Gson;
import com.google.gson.JsonElement;
import com.google.gson.JsonObject;
import com.google.gson.JsonParser;
import com.twitter.hbc.core.endpoint.StatusesFilterEndpoint;
import com.twitter.hbc.core.endpoint.StreamingEndpoint;

import io.socket.client.Ack;
import io.socket.client.IO;
import io.socket.emitter.Emitter;

import java.io.IOException;
import java.io.Serializable;
import java.net.URISyntaxException;
import java.net.UnknownHostException;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.Date;
import java.util.HashMap;
import java.util.HashSet;
import java.util.Iterator;
import java.util.LinkedHashMap;
import java.util.List;
import java.util.Map;
import java.util.Properties;
import java.util.Set;
import java.util.concurrent.TimeUnit;

public class TwitterStreamAnalytics {
	
	public static Map<String, Integer> tickerVolumeMap = new HashMap<String, Integer>();
	final static Logger logger = Logger.getLogger(TwitterStreamAnalytics.class);
    final static String[] tickers = new String[]{"$aapl","$csco","$ibm","$intc","$msft","$gs","$jpm","$v","$axp","$trv","$ba","$cat","$cvx","$xom","$ge","$jnj","$ko","$mcd","$mrk","$nke","$pfe","$pg","$vz","$wmt","$dis","$hd","$mmm","$utx","$unh","$vixy","$dia","$dwdp","$tlt","$uup","$gld","$dbc"};
    final static String[] tickers_plain = new String[]{"AAPL","CSCO","IBM","INTC","MSFT","GS","JPM","V","AXP","TRV","BA","CAT","CVX","XOM","GE","JNJ","KO","MCD","MRK","NKE","PFE","PG","VZ","WMT","DIS","HD","MMM","UTX","UNH","VIXY","DIA","DWDP","TLT","UUP","GLD","DBC"};


    @SuppressWarnings("serial")
	public static void main(String[] args) throws Exception {
        // set up the execution environment
        final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
        
        logger.info("Flink Twitter Volume Streamer has started");
        
        //SELECT "value" FROM "twitter"."autogen"."raw" WHERE time > now() - 24h
        
        Properties props = new Properties();
        props.setProperty(TwitterSource.CONSUMER_KEY, "iwHrgTB64nnILxMQoEWk781mJ");
        props.setProperty(TwitterSource.CONSUMER_SECRET, "xFMilSfdHk7MVuLHDeJ0ZSuo3qT94ELofCM55Iwb0TsHX1L7EG");
        props.setProperty(TwitterSource.TOKEN, "869291635191857152-OJqDKstcIbiwzJUvsXzxfMPqIWYzecS");
        props.setProperty(TwitterSource.TOKEN_SECRET, "2KxVbY7CKB5tJ1jrBjmoS9vQt5jvqbHTcJts6XCXvlUiC");
        
        TwitterSource source = new TwitterSource(props);
                
        String socket_url = args[0];
        String window_time = args[1];
        String influx_url = args[2];
        
        
        for (String key : tickers)
        	tickerVolumeMap.put(key, 0);
		
		source.setCustomEndpointInitializer(new TwitterFilterEndpoint(tickers));
		
		env.setStateBackend(new FsStateBackend("file:///tmp/checkpoints"));
		  env.enableCheckpointing(4000);
		  env.getCheckpointConfig().setCheckpointingMode(CheckpointingMode.EXACTLY_ONCE);
		  env.getCheckpointConfig().setCheckpointTimeout(60000);
		  env.getCheckpointConfig().setMaxConcurrentCheckpoints(1);
		  env.setRestartStrategy(RestartStrategies.fixedDelayRestart(10, 10000L));

		env.addSource(source)
            .flatMap(new ExtractHashTagsSymbols(tickers,influx_url))
            .keyBy(0)
            .timeWindow(Time.seconds(Integer.parseInt(window_time)))
            .sum(1)
            .timeWindowAll(Time.seconds(1))
            .apply(new GetVolume(tickerVolumeMap))
			.addSink(new SinkFunction<JSONObject>(){
    			
    			public void invoke(JSONObject value) throws Exception {
    				
    				LinkedHashMap<String, String[]> jsonOrderedMap = new LinkedHashMap<String, String[]>();
    				String[] TickerCount = new String[tickers.length];
    				    				
    				//Ordering the Twitter Hashtags
    				for( int i = 0; i < tickers.length; i++)
    				{	
    	                String val = value.getString(tickers[i]);
    	                TickerCount[i] = val;

    				}
    				
    				jsonOrderedMap.put("t", tickers_plain);
    				jsonOrderedMap.put("c", TickerCount);

    				JSONObject orderedJson = new JSONObject(jsonOrderedMap);
    				orderedJson.put("ts", value.getString("timestamp"));
    				
    				System.out.println("Twitter Volume:"+orderedJson.toString());
    				
    				pushToInflux(orderedJson,influx_url);
    				
    				}
    		});


        env.execute("Twitter Volume");
    }
    
    public static void pushToInflux(JSONObject orderedJson,String influx_url) throws JSONException{
    	// Connect to InfluxDB
    	InfluxDB influxDB = InfluxDBFactory.connect(influx_url, "admin", "*india112");

        // Create a database
        String dbName = "twitter";
        String volume = orderedJson.toString();
        String time_str = orderedJson.get("ts").toString();
        long time_long = (Long.parseLong(time_str));
        
        BatchPoints batchPoints = BatchPoints
                .database(dbName)
                .consistency(InfluxDB.ConsistencyLevel.ALL)
                .build();
        
        Point point1 = Point.measurement("volume")
                .time(time_long, TimeUnit.MILLISECONDS)
                .addField("value", volume)
                .build();
        
        batchPoints.point(point1);

        // Write them to InfluxDB
        influxDB.write(batchPoints);

    }
    
    public static void pushToInfluxRaw(JsonNode tweetJson,String influx_url) throws JSONException{
    	// Connect to InfluxDB
    	InfluxDB influxDB = InfluxDBFactory.connect(influx_url, "admin", "*india112");

        // Create a database
        String dbName = "twitter";
        
        long time_long = tweetJson.get("timestamp_ms").asLong();
        String time_str= tweetJson.get("text").asText();
        
        
        BatchPoints batchPoints = BatchPoints
                .database(dbName)
                .consistency(InfluxDB.ConsistencyLevel.ALL)
                .build();
        
        Point point1 = Point.measurement("raw")
                .time(time_long, TimeUnit.MILLISECONDS)
                .addField("value", time_str)
                .build();
        
        batchPoints.point(point1);

        // Write them to InfluxDB
        influxDB.write(batchPoints);

    }
    
    public static void pushToSocket(String value,String socket_url) throws UnknownHostException, IOException, ClassNotFoundException, URISyntaxException 
	  {
		  
		    IO.Options opts = new IO.Options();
		    opts.timeout=500;
		    opts.reconnectionAttempts = 1;
		    opts.reconnectionDelay = 50;
		    opts.reconnection = true;

			io.socket.client.Socket socket = IO.socket(socket_url,opts);
			
			socket.on("connect", new Emitter.Listener() {

			  @Override
			  public void call(Object... args) {
				  socket.emit("data", value, new Ack() {
					  @Override
					  public void call(Object... args) {
						  Boolean response = (Boolean)args[0];
						  System.out.println("Server Response:"+response);
						  socket.disconnect();
						  socket.close();
					  }
					});
			  }
			}).on("connect_timeout", new Emitter.Listener() {
	            @Override
	            public void call(Object... objects) {
	                System.out.println("timeout");
	            }
	        }).on("disconnect", new Emitter.Listener() {

			  @Override
			  public void call(Object... args) {
				  System.out.println("Socket Disconnect");
				  socket.disconnect();
			  }

			});
			
			socket.connect();
		}

    private static class TweetsCount implements Serializable {
        private static final long serialVersionUID = 1L;
        private Date windowStart;
        private Date windowEnd;
        private String hashTag;
        private int count;

        public TweetsCount(long windowStart, long windowEnd, String hashTag, int count) {
            this.windowStart = new Date(windowStart);
            this.windowEnd = new Date(windowEnd);
            this.hashTag = hashTag;
            this.count = count;
        }

        @Override
        public String toString() {
            return "TweetsCount{" +
                    "windowStart=" + windowStart +
                    ", windowEnd=" + windowEnd +
                    ", hashTag='" + hashTag + '\'' +
                    ", count=" + count +
                    '}';
        }
    }

    private static class ExtractHashTagsSymbols implements FlatMapFunction<String, Tuple2<String, Integer>> {

        private static final ObjectMapper mapper = new ObjectMapper();
		private final String[] tickers;
		private final String influx_url;

        public ExtractHashTagsSymbols(String[] tickers,String influx_url) {
			// TODO Auto-generated constructor stub
        	this.tickers = tickers;
        	this.influx_url= influx_url;

		}

		@Override
        public void flatMap(String tweetJsonStr, Collector<Tuple2<String, Integer>> collector) throws Exception {
			if(tweetJsonStr.length()==0){
				return;
			}
            JsonNode tweetJson = mapper.readTree(tweetJsonStr);
            final Set<String> VALUES = new HashSet<String>(Arrays.asList(
        		    this.tickers
        		));
            JsonNode entities = tweetJson.get("entities");
            if (entities == null) return;
            
            
            LinkedHashMap<String, String> jsonOrderedMap = new LinkedHashMap<String, String>();

			JSONObject orderedJson = new JSONObject(jsonOrderedMap);
			orderedJson.put("ts", tweetJson.get("timestamp_ms").asLong());
			orderedJson.put("tweet", tweetJson.get("text"));
			
			pushToInfluxRaw(tweetJson,influx_url);
            
            JsonNode symbols = entities.get("symbols");
            
            if (symbols== null) return;
            
            List<String> symbolList = new ArrayList<String>();
            
            ArrayList<String> blacklistedList = new ArrayList<String>();
            
            // Iterate Symbols and convert to list
            for (Iterator<JsonNode> iter = symbols.getElements(); iter.hasNext();) {
                JsonNode node = iter.next();
                String symbol = node.get("text").getTextValue();
                symbol = symbol.toLowerCase();
                if ((symbol.matches("\\w+")) && (VALUES.contains('$'+symbol)) ) {
                	symbolList.add('$'+symbol);
                }
            }

            //Push the unique list
            for (String element : symbolList) {
            	collector.collect(new Tuple2<>(element, 1));
            }
        }
    }

    private static class FilterHashTags implements FilterFunction<Tuple2<String, Integer>> {
        @Override
        public boolean filter(Tuple2<String, Integer> hashTag) throws Exception {
            return hashTag.f1 != 1;
        }
    }

private static class GetVolume implements AllWindowFunction<Tuple2<String,Integer>, JSONObject, TimeWindow> {
       
    
	private Map<String, Integer> tickerVolumeMap;

	public GetVolume(Map<String, Integer> tickerVolumeMap) {
		// TODO Auto-generated constructor stub
		this.tickerVolumeMap = tickerVolumeMap;
	}

	public void apply(TimeWindow window, Iterable<Tuple2<String, Integer>> tickerTweets, Collector<JSONObject> out) throws Exception {
        Gson gsonObj = new Gson();
        Map<String, Integer> tickerVolumeMapper = new HashMap<String, Integer>(this.tickerVolumeMap);
        for (Tuple2<String, Integer> tweet : tickerTweets) {
        	//System.out.println(tweet.f0+":"+tweet.f1);
        	Integer value = tickerVolumeMapper.get(tweet.f0);
        	tickerVolumeMapper.put(tweet.f0, value+tweet.f1);
        }
		String jsonStr = gsonObj.toJson(tickerVolumeMapper);
		JSONObject json = new JSONObject(tickerVolumeMapper);
		json.put("timestamp", window.getEnd());
		out.collect(json);
    }

}

public static class TwitterFilterEndpoint implements TwitterSource.EndpointInitializer, Serializable {

    private String[] hashtags;

    public TwitterFilterEndpoint(String[] hashtags) {
        this.hashtags=hashtags;
    }

    public StreamingEndpoint createEndpoint() {
        StatusesFilterEndpoint statusesFilterEndpoint = new StatusesFilterEndpoint();
        statusesFilterEndpoint.trackTerms(Arrays.asList(hashtags));
        statusesFilterEndpoint.stallWarnings(false);
        statusesFilterEndpoint.delimited(false);
        return statusesFilterEndpoint;
    }

}

}